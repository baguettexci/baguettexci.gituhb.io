---
title: SMS Spam
date: 2018-10-15
tags: 
  - machine learning
  - data science
header:
  image: ""
excerpt: "Machine Learning, Data Science"
mathjax: "true"
---

## 1) Setup
### Load packages
```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
```
### Load & Viewing the Data
```python
sms = pd.read_csv('SMSSpamCollection', sep='\t', names=["label", "message"])
sms.head()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>message</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ham</td>
      <td>Go until jurong point, crazy.. Available only ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ham</td>
      <td>Ok lar... Joking wif u oni...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>spam</td>
      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ham</td>
      <td>U dun say so early hor... U c already then say...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ham</td>
      <td>Nah I don't think he goes to usf, he lives aro...</td>
    </tr>
  </tbody>
</table>

## 2) Exploratory data analysis

```python
sms = pd.read_csv('SMSSpamCollection', sep='\t', names=["label", "message"])
sms.head()
```

```python
sms.describe()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>message</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>5572</td>
      <td>5572</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>2</td>
      <td>5169</td>
    </tr>
    <tr>
      <th>top</th>
      <td>ham</td>
      <td>Sorry, I'll call later</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>4825</td>
      <td>30</td>
    </tr>
  </tbody>
</table>


```python
sms.groupby('label').describe()
```  
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th colspan="4" halign="left">message</th>
    </tr>
    <tr style="text-align: right;">
      <th>label</th>
      <th>count</th>
      <th>unique</th>
      <th>top</th>
      <th>freq</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>ham</th>
      <td>4825</td>
      <td>4516</td>
      <td>Sorry, I'll call later</td>
      <td>30</td>
    </tr>
    <tr>
      <th>spam</th>
      <td>747</td>
      <td>653</td>
      <td>Please call our customer service representativ...</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
```python
sms["label"].value_counts().plot(kind = 'pie', explode = [0, 0.1], figsize = (6, 6), autopct = '%1.1f%%', shadow = True)
plt.ylabel("Spam vs Ham")
plt.legend(["Ham", "Spam"])
plt.show()
```
<img src="{{ site.url }}{{ site.baseurl }}/images/SMS Spam/piechart.jpg" alt="">

Insert a new column to detect how long the text messages are
```python
sms['length'] = sms['message'].apply(len)
sms.head()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>message</th>
      <th>length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ham</td>
      <td>Go until jurong point, crazy.. Available only ...</td>
      <td>111</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ham</td>
      <td>Ok lar... Joking wif u oni...</td>
      <td>29</td>
    </tr>
    <tr>
      <th>2</th>
      <td>spam</td>
      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>
      <td>155</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ham</td>
      <td>U dun say so early hor... U c already then say...</td>
      <td>49</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ham</td>
      <td>Nah I don't think he goes to usf, he lives aro...</td>
      <td>61</td>
    </tr>
  </tbody>
</table>
View the frequency count on a histogram
```python
sms['length'].plot(bins=50, kind='hist') 
```
<img src="{{ site.url }}{{ site.baseurl }}/images/SMS Spam/hist.jpg" alt="">
<br/>
See if message length is a distinguishing feature between ham and spam
```python
sms.hist(column='length', by='label', bins=50,figsize=(12,4))
```
<img src="{{ site.url }}{{ site.baseurl }}/images/SMS Spam/hist2.jpg" alt="">
<br/>
Seems like we discover a trend that spam messages tend to have more characters.

### Word Cloud
Create a word cloud to see which are the words frequently occurring in spam or ham messages
```python
from wordcloud import WordCloud, STOPWORDS
from os import path
from PIL import Image

# Separate sms into spam/ham
spam = sms[sms['label'] == 'spam']
ham = sms[sms['label'] == 'ham']
```
Spam
```python
stopwords_1 = set(STOPWORDS)
k = (' '.join(spam['message']))

# Input mask image
spam_mask = np.array(Image.open(path.join("Spam.png")))
# Generate a word cloud image
wordcloud = WordCloud(background_color="white", colormap='plasma', mask=spam_mask, width = 2500, height = 500, collocations=False, 
                      max_words=300, stopwords=stopwords_1, relative_scaling=0.2).generate(k)
plt.figure(figsize=(15,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.grid(False)
plt.tight_layout()
plt.show()
```
<img src="{{ site.url }}{{ site.baseurl }}/images/SMS Spam/spamcloud.jpg" alt="">
Ham
```python
stopwords_1 = set(STOPWORDS)
k = (' '.join(ham['message']))

# Input mask image
ham_mask = np.array(Image.open(path.join("Ham.png")))

# Generate a word cloud image
wordcloud = WordCloud(background_color="white", colormap='plasma', mask=ham_mask, width = 2500, height = 500, collocations=False, 
                      max_words=300, stopwords=stopwords_1, relative_scaling=0.2).generate(k)
plt.figure(figsize=(15,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.grid(False)
plt.tight_layout()
plt.show()
```
<img src="{{ site.url }}{{ site.baseurl }}/images/SMS Spam/hamcloud.jpg" alt="">
* Words such as 'FREE', 'reply', 'claim', 'prize' occurred often in spam messages
* Words such as 'go', 'will', 'Ok', 'good' occurred often in ham messages
* The word 'call' and 'now' seems to be occurring frequently in both spam and ham messages.

## 3) Text Preprocessing
Define a function for processing the text messages
```python
import string
from nltk.corpus import stopwords

def text_process(text):
    # Remove any punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    
    # Remove any stopwords
    # NLTK's stopwords assumes words are all lowercased
    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]

    #Join the characters again to form the string
    return " ".join(text)
```
Apply the function on the text messages
```python
messages = sms['message'].apply(text_process)
messages.head()
```
{% highlight text %}
0    Go jurong point crazy Available bugis n great ...
1                              Ok lar Joking wif u oni
2    Free entry 2 wkly comp win FA Cup final tkts 2...
3                  U dun say early hor U c already say
4          Nah dont think goes usf lives around though
Name: message, dtype: object
{% endhighlight %}

### Bag of words
Create a set of features indicating the number of times an observation's text contains a particular word, using a bag of words model.
Bag of words models output a feature for every unique word in text data, with each feature containing a count of occurrences in observations. The output would results in a matrix that can contain thousands of features and it would likely be a sparse matrix as most words do not occur in most observations.
```python
from sklearn.feature_extraction.text import CountVectorizer
# Create a bag of words feature matrix
count = CountVectorizer()
bag_of_words = count.fit_transform(messages)
```
View the shape of the feature matrix
```python
bag_of_words.shape
```
{% highlight text %}
(5572, 9437)
{% endhighlight %}
We had 9437 features, let's view the matrix
```python
bag_of_words.toarray()
```
{% highlight text %}
array([[0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       ...,
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0],
       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)
{% endhighlight %}
Indeed it's a sparse matrix

### TF-IDF
Weight the words by their importance to an observation by the method of term frequencyâ€“inverse document frequency
$$tf{\text -}idf(t,d) = tf(t,d)\times idf(t)$$

```python

```
{% highlight text %}

{% endhighlight %}
